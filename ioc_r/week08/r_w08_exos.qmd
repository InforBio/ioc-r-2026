---
title: "Week 8 - Hands-On Examples"
format: 
  html: default
  # pdf: default
date: "2025-03-11"
date-format: " "
categories: 
  - week08
  - exercise
editor_options: 
  chunk_output_type: console
---

The R script is available here:
[link](https://raw.githubusercontent.com/InforBio/IOC/refs/heads/main/ioc_r/week08/r_w08_exos.R)

## Goals

- Clean, reshape, and manipulate real-world data using {`dplyr`} and {`tidyr`} 
- Integrate tidy data into downstream analysis (e.g., for visualization or statistical analysis)

## Install {tidyverse} and Load the Package

```{r}
# install.packages("tidyverse")
library(tidyverse)
```


## Mini Data Project

This mini data project is based on a real project that focuses on gene expression across different time points.

A researcher has measured the expression levels of **20 genes** (anonymed as 1 to 20) using the RT-qPCR technique.
The gene expression was assessed in **two structures** of the mouse brain.
Mice ranged in age from 10 to 60 days (**10, 15, 20, 25, 30, 35, 40, 45, 50, 60 days**),
and the experiment was repeated with both **male** and **female** mice,
with **6 animals** (named from A to F) in each group.

According to the researcher, the data was stored in two files, one for each brain structure.
Within each file, **rows represent the different ages,
and columns represent the gene, sex, and animal.**

A small Gaussian noise has been added to the original data, preserving the overall structure.

The data is available in two CSV files:

- [data_anonym_struc1_noise.csv](../exos_data/data_anonym_struc1_noise.csv)
- [data_anonym_struc2_noise.csv](../exos_data/data_anonym_struc2_noise.csv)

We will focus on the data from the brain structure 1.

### Import the Data

1. Please download the `data_anonym_struc1_noise.csv` file.
Observe your data file:

- Is there a header line? 
- What is the separator between columns?
- Which character was used for decimal points?
- Which character was used for missing data (between two seperators where there's no value)?

:::{.callout-tip title="Preview File"}
You can preview the data file in different ways, such as:

- Opening it with a text editor;
- Clicking the file name and selecting "View File" in the RStudio *File Pane*;
- Or by using the terminal: `head -n2 data_anonym_struc1_noise.csv` (to view the first 2 lines) or `more data_anonym_struc1_noise.csv` (to scroll through the file and quit by typing `q`), which is **recommended for large files**.

:::

2. Import the `data_anonym_struc1_noise.csv` into RStudio, you can use either:

- the `read_csv2()` from the package {`readr`} (`?readr::read_csv2`), or
- use the click-button way and copy-paste the code in your script.

**Don't forget to use/select the appropriate parameters to make sure you import correctly the data.**

Name the data as `data1`.
Convert your imported data to tibble format if it's not the case.

What is the data dimension?

```{r}
data1 <- readr::read_csv2(
  file = "../exos_data/data_anonym_struc1_noise.csv",
  locale = locale(decimal_mark = ",")
)

# or use the read_delim() with appropriate parameters
# data1 <- read_delim(
#   "../exos_data/data_anonym_struc1_noise.csv", 
#   delim = ";", locale = locale(decimal_mark = ",")
# )
```

3. Show the first 10 columns of your data.

```{r}
# classic way
data1[, 1:10]

# use select()
select(data1, 1:10)
```

4. Rename the first column as `age`.

```{r}
data1 <- data1 |>
  rename(age = ...1)

```

### Reshape the Data

How should the data be organized?

5. Reshape data to "tidy" format with the `pivot_longer()` function.
(tidy format: each variable is a column, each observation is a row.)
What are the columns to be included to pivot into longer format?
 
```{r}
# use column index
data1_long <- data1 |>
  pivot_longer(cols = -1, names_to = "id", values_to = "value")

# use column name
# data1_long <- data1 |>
#   pivot_longer(cols = -age, names_to = "id", values_to = "value")

data1_long 
```

6. Add a column `struc` which contains the name of the measured structure `s1`.

```{r}
data1_long <- data1_long |>
  mutate(struc = "s1")
data1_long
```

7. Extract information about gene, sex and animal from the column `id` using the `extract()` function. Name the new columns as "gene_id", "sex" and "animal".

**Hint**: Find the patterns for the extraction.
You can use AI to help you to write the regular expression.

```{r}
# check how id (the colnames before reshape) was constructed.
head(data1_long$id)
tail(data1_long$id)

data1_long <- data1_long |>
  extract(
    col = id,
    into = c("gene_id", "sex", "animal"),
    regex = "([0-9]+)([MF])([A-F])"
  )
```

If you want to write all previous codes together:

```{r}
#| eval: false

data1_long <- readr::read_csv2(
    file = "../exos_data/data_anonym_struc1_noise.csv",
    locale = locale(decimal_mark = ",")
  ) |>
  rename(age = ...1) |> # not necessary if the next line "cols" based on index
  pivot_longer(cols = -1, names_to = "id", values_to = "value") |>
  mutate(struc = "s1") |>
  extract(
    col = id,
    into = c("gene_id", "sex", "animal"),
    regex = "([0-9]+)([MF])([A-F])"
  )
```

Now, the data is ready for downstream analysis.

### Manipulate the Data

For question 8 to 11, let's focus on gene 1 from the data.

8. At age of 10 days, which animal has the highest expression value for gene 1 overall?
And which animal has the highest expression value in each sex?

```{r}
# overall
data1_long |>
  filter(gene_id == "1" & age == 10) |>
  arrange(desc(value)) |>
  slice(1)


# in each sex
data1_long |>
  filter(gene_id == "1" & age == 10) |>
  group_by(sex) |>
  arrange(desc(value)) |>
  slice(1)
```

9. Is there any missing value for gene 1?
If yes, how to remove lines with NA?

```{r}
data1_long |>
  filter(gene_id == "1") |>
  pull(value) |>
  is.na() |>
  table()

data1_long |>
  filter(gene_id == "1") |>
  drop_na(value)
```

10. After removing NAs, how many animals are there for each sex in gene 1?

```{r}
data1_long |>
  filter(gene_id == "1") |>
  drop_na(value) |>
  group_by(sex) |>
  count()
```

11. Summarize the median, mean, and standard deviation of gene 1 expression for both sexes.

```{r}
data1_long |>
  filter(gene_id == "1") |>
  drop_na(value) |>
  group_by(sex) |>
  summarise(
    median_gene1 = median(value),
    mean_gene1 = mean(value),
    sd_gene1 = sd(value)
  )
```

### Explore the Data

What kind of analysis would you like to perform with this data?

In statistics, it's common to begin by exploring the dataset as a whole and visualizing the relationships between different variables.
The basic R function `pairs()` (`?pairs`) is useful for creating a matrix of scatter plots to examine the relationships between each pair of continuous variables.

For instance, we can explore the relationships between continuous variables such as age and the expression levels of genes 1, 2, 3, *etc.*

12. How will you reshape the `data1_long` to provide the necessary data for the `pairs()` function?

```{r}
data1_wider <- data1_long |>
  pivot_wider(
    names_from = "gene_id",
    values_from = "value",
    names_prefix = "gene" # to avoid name starts with number
  )

data1_wider
```

To save space, we will focus on examining the relationship between age and the first 5 genes.

13. What did you observe from these scatter plots?

```{r}
#| fig-width: 12
#| fig-height: 12

## put histograms on the diagonal
panel.hist <- function(x, ...) {
  usr <- par("usr")
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
## put (absolute) correlations on the upper panels,
## with size proportional to the correlations.
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y, use = "na.or.complete")) # modified to allow NA
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste0(prefix, txt)
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = cex.cor * r)
}

pairs(
  x = select(data1_wider, age, gene1:gene5),
  diag.panel = panel.hist,
  lower.panel = panel.smooth,
  upper.panel = panel.cor
)
```


14. Calculate the correlation between gene 1 and 2. (`?cor`)

```{r}
cor(
  x = data1_wider$gene1,
  y = data1_wider$gene2,
  use = "na.or.complet"
) # by default use the pearson's method
```

It seems that there are two groups of mice that express genes 4 and 5 in a similar way.

15. Draw a scatter plot using {`ggplot2`} to show the expression levels of genes 4 and 5.
Color the points by different categorical variables that we have, *i.e.*, age, sex, and animal.

Is there any categorical variable that can explain the groups we observed in the figure?

```{r}
p_age <- ggplot(data = data1_wider, aes(x = gene4, y = gene5)) +
  geom_point(aes(color = age)) +
  labs(title = "Expression Level of Genes 4 and 5") +
  theme_light()
p_age

p_sex <- ggplot(data = data1_wider, aes(x = gene4, y = gene5)) +
  geom_point(aes(color = sex)) +
  labs(title = "Expression Level of Genes 4 and 5") +
  theme_light()
p_sex

p_animal <- ggplot(data = data1_wider, aes(x = gene4, y = gene5)) +
  geom_point(aes(color = animal)) +
  labs(title = "Expression Level of Genes 4 and 5") +
  theme_light()
p_animal
```


## Bonus

Use the `read.table()` function to import the data and continue to reshape the data based on the imported data.

(Check the approporiate parameters to be included with `?read.table`)

```{r}
#| code-fold: true
#| code-summary: "Correction"

# import data with the basic function
data1 <- read.table(
  file = "../exos_data/data_anonym_struc1_noise.csv",
  header = TRUE, sep = ";", dec = ",", na.strings = ""
)
# convert to a tibble
data1 <- as_tibble(data1)

# transform to long format and 
data_long <- data1 |>
  rename(age = X) |>
  pivot_longer(cols = -1, names_to = "id", values_to = "value") |>
  mutate(
    id = sub("X", "", id), # remove the X in ID
    struc = paste0("s", 1) # store info of brain structure
  ) |>
  extract( # extract column into multiple columns
    id,
    into = c("gene_id", "sex", "animal"),
    regex = "([0-9]+)([MF])([A-F])"
  )

data_long
```

---

#### Good job! 👏👏 You've made great progress in mastering data manipulation techniques.


